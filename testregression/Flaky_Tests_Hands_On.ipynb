{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flaky Tests: Hands On",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ot4_Grsl4Ff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import time\n",
        "from threading import Thread\n",
        "\n",
        "class app(Thread):\n",
        "  def __init__ (self):\n",
        "    Thread.__init__(self)\n",
        "    self.res = 0\n",
        "\n",
        "  def setResult(self, result):\n",
        "    self.res = result\n",
        "\n",
        "  def getResult(self):\n",
        "    return self.res\n",
        "\n",
        "  def run(self):\n",
        "    sleep_length = random.random() * 10\n",
        "    time.sleep(sleep_length)\n",
        "    self.setResult(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcHJ3m2bowUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import unittest\n",
        "import time\n",
        "\n",
        "class AppTestCase(unittest.TestCase):\n",
        "    def test_app_function(self):\n",
        "      app_test = app()\n",
        "      app_test.start()\n",
        "      time.sleep(7)\n",
        "      self.assertEqual(100, app_test.getResult())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edIDK3saqhw-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "1f5c8344-535f-408d-d446-2ef965e6feed"
      },
      "source": [
        "suite = unittest.TestLoader().loadTestsFromTestCase(AppTestCase)\n",
        "unittest.TextTestRunner().run(suite)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "======================================================================\n",
            "FAIL: test_app_function (__main__.AppTestCase)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-51-25320b01c54c>\", line 9, in test_app_function\n",
            "    self.assertEqual(100, app_test.getResult())\n",
            "AssertionError: 100 != 0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 7.006s\n",
            "\n",
            "FAILED (failures=1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=1 errors=0 failures=1>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDOmggQk1lnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "37a9d6db-44d8-4abb-f32b-2abe3ce718eb"
      },
      "source": [
        "suite = unittest.TestLoader().loadTestsFromTestCase(AppTestCase)\n",
        "unittest.TextTestRunner().run(suite)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 7.009s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    }
  ]
}